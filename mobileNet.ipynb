{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6183f4fb-8c1d-4e4c-b271-28a78dacb8ab",
   "metadata": {},
   "source": [
    "# Dependecies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a54435a2-c5be-4766-a151-0923cdfad7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\shawn\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\shawn\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.6.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 882.6 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.8/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.8/2.4 MB 581.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 645.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 705.9 kB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\shawn\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\shawn\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\shawn\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.4-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from albumentations) (1.13.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from albumentations) (6.0.1)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting albucore==0.0.23 (from albumentations)\n",
      "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations)\n",
      "  Downloading stringzilla-3.11.3-cp312-cp312-win_amd64.whl.metadata (81 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\n",
      "  Downloading simsimd-6.2.1-cp312-cp312-win_amd64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shawn\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.6.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading albumentations-2.0.4-py3-none-any.whl (289 kB)\n",
      "Downloading albucore-0.0.23-py3-none-any.whl (14 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/39.4 MB 2.8 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 1.0/39.4 MB 2.4 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.3/39.4 MB 1.8 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 1.6/39.4 MB 1.8 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 1.8/39.4 MB 1.8 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 2.1/39.4 MB 1.7 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 2.6/39.4 MB 1.7 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 2.9/39.4 MB 1.7 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 3.1/39.4 MB 1.7 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 3.4/39.4 MB 1.7 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 3.7/39.4 MB 1.7 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 4.2/39.4 MB 1.6 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 4.5/39.4 MB 1.6 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 4.7/39.4 MB 1.6 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 5.2/39.4 MB 1.6 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 5.5/39.4 MB 1.6 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 5.8/39.4 MB 1.6 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 5.8/39.4 MB 1.6 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 6.0/39.4 MB 1.5 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 6.6/39.4 MB 1.5 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 6.8/39.4 MB 1.5 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 7.1/39.4 MB 1.5 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 7.3/39.4 MB 1.5 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 7.6/39.4 MB 1.5 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 8.1/39.4 MB 1.5 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 8.4/39.4 MB 1.5 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 8.9/39.4 MB 1.5 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 9.2/39.4 MB 1.5 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 9.4/39.4 MB 1.5 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 10.0/39.4 MB 1.6 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 10.2/39.4 MB 1.6 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 10.5/39.4 MB 1.5 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 10.5/39.4 MB 1.5 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 10.7/39.4 MB 1.5 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 11.3/39.4 MB 1.5 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 11.5/39.4 MB 1.5 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 11.8/39.4 MB 1.5 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 12.1/39.4 MB 1.5 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 12.6/39.4 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 12.8/39.4 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 13.4/39.4 MB 1.5 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 13.6/39.4 MB 1.5 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 14.2/39.4 MB 1.5 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 14.4/39.4 MB 1.6 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 14.9/39.4 MB 1.6 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 15.2/39.4 MB 1.6 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 15.5/39.4 MB 1.6 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 16.0/39.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 16.5/39.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 16.8/39.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 17.0/39.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 17.3/39.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 17.8/39.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 18.4/39.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 18.6/39.4 MB 1.6 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 19.1/39.4 MB 1.6 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 19.4/39.4 MB 1.6 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 19.9/39.4 MB 1.6 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 20.2/39.4 MB 1.6 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 20.7/39.4 MB 1.6 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 21.0/39.4 MB 1.6 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 21.5/39.4 MB 1.6 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 22.0/39.4 MB 1.7 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 22.3/39.4 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 22.8/39.4 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 23.1/39.4 MB 1.7 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 23.3/39.4 MB 1.7 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 23.3/39.4 MB 1.7 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 23.6/39.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 23.6/39.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 23.9/39.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 23.9/39.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 24.1/39.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 24.6/39.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 24.9/39.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 25.2/39.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 25.4/39.4 MB 1.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 26.0/39.4 MB 1.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 26.2/39.4 MB 1.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 26.2/39.4 MB 1.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 26.2/39.4 MB 1.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 26.5/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 26.5/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 26.5/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 26.7/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 26.7/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 26.7/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 26.7/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 26.7/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 26.7/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 26.7/39.4 MB 1.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.0/39.4 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.0/39.4 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.0/39.4 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.0/39.4 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.0/39.4 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.0/39.4 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.0/39.4 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.0/39.4 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.0/39.4 MB 1.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 27.3/39.4 MB 1.3 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 27.3/39.4 MB 1.3 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 27.5/39.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 27.8/39.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 28.0/39.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 28.0/39.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 28.3/39.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 28.3/39.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 28.6/39.4 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 28.6/39.4 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 28.8/39.4 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 29.4/39.4 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 29.6/39.4 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 29.9/39.4 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 30.4/39.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 30.4/39.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 30.9/39.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 31.2/39.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 31.2/39.4 MB 1.3 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 31.7/39.4 MB 1.3 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 32.0/39.4 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 32.2/39.4 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 32.5/39.4 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 32.5/39.4 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 32.8/39.4 MB 1.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 33.0/39.4 MB 1.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 33.3/39.4 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 33.6/39.4 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 33.8/39.4 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 34.1/39.4 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 34.3/39.4 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 34.3/39.4 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 34.3/39.4 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 34.6/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 34.6/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 34.9/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 34.9/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 34.9/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 35.1/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 35.4/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 35.4/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 35.7/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 35.7/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 35.7/39.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 35.9/39.4 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 35.9/39.4 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 36.2/39.4 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 36.2/39.4 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 36.2/39.4 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 36.4/39.4 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 36.7/39.4 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 37.0/39.4 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 37.2/39.4 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 37.5/39.4 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 37.7/39.4 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 38.0/39.4 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 38.0/39.4 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 38.3/39.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  38.5/39.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/39.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/39.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/39.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.1/39.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 524.3 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 524.3 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 524.3 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 524.3 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 524.3 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.8/2.0 MB 353.3 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 1.0/2.0 MB 484.0 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.6/2.0 MB 650.5 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 650.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 713.0 kB/s eta 0:00:00\n",
      "Downloading simsimd-6.2.1-cp312-cp312-win_amd64.whl (87 kB)\n",
      "Downloading stringzilla-3.11.3-cp312-cp312-win_amd64.whl (80 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: stringzilla, simsimd, typing-extensions, opencv-python-headless, pydantic-core, albucore, pydantic, albumentations\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "Successfully installed albucore-0.0.23 albumentations-2.0.4 opencv-python-headless-4.11.0.86 pydantic-2.10.6 pydantic-core-2.27.2 simsimd-6.2.1 stringzilla-3.11.3 typing-extensions-4.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\shawn\\anaconda3\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install numpy matplotlib opencv-python\n",
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1751bd-1f3e-41a8-8527-b873113d3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): Conv2dNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shawn\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shawn\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Load the pretrained MobileNetV3 model\n",
    "model = models.mobilenet_v3_small(pretrained=True)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7b5e5a-57d2-4983-a403-b224adffc82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): Conv2dNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1024, out_features=15, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define number of climbing hold colors (adjust based on dataset)\n",
    "num_classes = 15  # Example: Red, Blue, Yellow, Green, Orange\n",
    "\n",
    "# Modify the classifier head\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3603e16c-0584-49c5-b20a-d7bed2e784ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images shape: 5\n",
      "Batch targets: [{'boxes': tensor([[1595., 2951., 1896., 3165.],\n",
      "        [1551., 2378., 1852., 2576.],\n",
      "        [1227., 2260., 1351., 2332.],\n",
      "        [2056., 1192., 2433., 1663.],\n",
      "        [ 764.,  160.,  920.,  310.],\n",
      "        [1371.,  527., 1481.,  675.],\n",
      "        [1469.,  563., 1619.,  659.],\n",
      "        [1591.,  765., 1774.,  875.],\n",
      "        [ 715., 1647., 1406., 2037.],\n",
      "        [2562.,  631., 2890., 1302.],\n",
      "        [2013.,  327., 2490.,  749.],\n",
      "        [1815.,  839., 2101., 1004.],\n",
      "        [2528.,    4., 2650.,  399.],\n",
      "        [2710.,  381., 2876.,  631.],\n",
      "        [2508.,  941., 2626., 1314.],\n",
      "        [2634., 1236., 2834., 1512.],\n",
      "        [2165., 1568., 2470., 1803.],\n",
      "        [1955., 1651., 2129., 1841.],\n",
      "        [2023., 1737., 2047., 1737.],\n",
      "        [2127., 2294., 2386., 2528.],\n",
      "        [1394., 1801., 1761., 2005.],\n",
      "        [1454., 2716., 1819., 2895.],\n",
      "        [2083., 3219., 2155., 3311.],\n",
      "        [ 789., 2668.,  955., 2814.],\n",
      "        [1508.,    0., 1837.,  154.],\n",
      "        [1714.,  375., 1941.,  619.],\n",
      "        [1116., 1084., 1358., 1374.],\n",
      "        [1314.,    0., 1450.,   50.],\n",
      "        [1174.,  170., 1404.,  365.],\n",
      "        [ 833.,  555., 1116.,  727.],\n",
      "        [ 615.,  968., 1124., 1446.],\n",
      "        [1470., 1232., 1913., 1572.],\n",
      "        [ 953., 1490., 1063., 1560.],\n",
      "        [1903., 2816., 2025., 2899.],\n",
      "        [2139., 3061., 2253., 3125.],\n",
      "        [1815., 2051., 2233., 2416.],\n",
      "        [2448., 1605., 2620., 1817.],\n",
      "        [1406.,  184., 1684.,  543.],\n",
      "        [1204.,  925., 1438., 1048.],\n",
      "        [ 929., 2496., 1486., 3097.],\n",
      "        [2618., 1522., 2774., 1667.],\n",
      "        [1873., 3133., 2013., 3241.],\n",
      "        [ 845., 2101.,  977., 2258.],\n",
      "        [1332., 2191., 1530., 2302.],\n",
      "        [1063., 1380., 1286., 1526.],\n",
      "        [1795., 2169., 1933., 2286.],\n",
      "        [1498.,  964., 1680., 1144.],\n",
      "        [1845., 1404., 1993., 1548.],\n",
      "        [1436., 1172., 1516., 1380.],\n",
      "        [ 735., 1448.,  943., 1663.],\n",
      "        [2650.,   68., 2768.,  240.],\n",
      "        [ 791., 2885.,  871., 2969.],\n",
      "        [2712.,  719., 2812.,  871.],\n",
      "        [2600.,  206., 2730.,  421.],\n",
      "        [2792.,  933., 2924., 1104.],\n",
      "        [2558., 1637., 2666., 1801.],\n",
      "        [2281., 2025., 2398., 2123.],\n",
      "        [2325., 2526., 2598., 2828.],\n",
      "        [2486., 2129., 2584., 2276.],\n",
      "        [2404., 2149., 2498., 2320.],\n",
      "        [1110., 2416., 1302., 2574.],\n",
      "        [2380., 2464., 2508., 2585.],\n",
      "        [2357., 2368., 2452., 2443.]]), 'labels': tensor([3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4,\n",
      "        0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 0, 1, 0, 0, 8, 8, 0, 0,\n",
      "        3, 6, 6, 1, 2, 2, 0, 3, 0, 6, 2, 4, 1, 1, 0])}, {'boxes': tensor([[1757., 2684., 2178., 2987.],\n",
      "        [ 184., 1215.,  685., 1673.],\n",
      "        [2050., 1897., 2352., 2077.],\n",
      "        [2117., 3307., 2215., 3422.],\n",
      "        [2307., 3128., 2518., 3314.],\n",
      "        [2736., 3276., 2986., 3429.],\n",
      "        [2159., 1122., 2377., 1276.],\n",
      "        [2204., 1442., 2435., 1660.],\n",
      "        [ 172.,  575.,  427.,  794.],\n",
      "        [ 281.,  987.,  518., 1141.],\n",
      "        [1256., 3026., 1467., 3218.],\n",
      "        [1640., 3327., 1884., 3570.],\n",
      "        [1916., 2423., 2198., 2596.],\n",
      "        [2544., 2577., 2756., 2782.],\n",
      "        [ 858., 2603., 1108., 2808.],\n",
      "        [1230., 2359., 1409., 2615.],\n",
      "        [2134.,  872., 2397., 1115.],\n",
      "        [ 963., 1225., 1104., 1429.],\n",
      "        [1461., 2301., 1634., 2506.],\n",
      "        [1435., 1449., 1583., 1679.],\n",
      "        [ 901.,  744., 1089.,  911.],\n",
      "        [1256., 1000., 1441., 1218.],\n",
      "        [2672., 2995., 2835., 3167.],\n",
      "        [2204., 2570., 2454., 2750.],\n",
      "        [2704., 1083., 2865., 1333.],\n",
      "        [1980., 1519., 2166., 1782.],\n",
      "        [1730.,  962., 1986., 1237.],\n",
      "        [1518., 3615., 1711., 3737.],\n",
      "        [ 813., 1577.,  941., 1776.],\n",
      "        [ 756.,  699.,  865.,  846.],\n",
      "        [1657., 1726., 1773., 1843.],\n",
      "        [1259., 1815., 1420., 1976.],\n",
      "        [1476., 3240., 1640., 3409.],\n",
      "        [1206., 3411., 1298., 3526.],\n",
      "        [1119., 2967., 1228., 3082.],\n",
      "        [1617., 2735., 1731., 2857.],\n",
      "        [2225., 1824., 2326., 1885.],\n",
      "        [1816., 1509., 1971., 1649.],\n",
      "        [2924., 1195., 2991., 1318.],\n",
      "        [2884., 1566., 3021., 1683.],\n",
      "        [2764., 1685., 2942., 1890.],\n",
      "        [2411., 1956., 2579., 2183.],\n",
      "        [2362., 3317., 2549., 3463.],\n",
      "        [2651., 3391., 2654., 3392.],\n",
      "        [2381., 3483., 2469., 3527.],\n",
      "        [1035., 1124., 1185., 1252.],\n",
      "        [ 956.,  891., 1075.,  991.],\n",
      "        [1022.,  840., 1022.,  842.],\n",
      "        [1090., 1262., 1182., 1353.],\n",
      "        [2015., 3034., 2128., 3182.],\n",
      "        [1941.,  814., 2099.,  978.],\n",
      "        [2436., 1037., 2598., 1118.],\n",
      "        [2250., 2270., 2426., 2475.],\n",
      "        [2751., 2112., 2881., 2278.],\n",
      "        [1908., 3090., 2026., 3210.],\n",
      "        [1357., 1953., 1454., 2094.],\n",
      "        [ 532., 1813.,  661., 1992.],\n",
      "        [ 670., 2097.,  744., 2150.],\n",
      "        [ 807., 2375.,  963., 2536.],\n",
      "        [1080., 2092., 1196., 2250.],\n",
      "        [1011., 1971., 1111., 2086.],\n",
      "        [1063., 3070., 1269., 3345.],\n",
      "        [2628., 1261., 2812., 1437.],\n",
      "        [2529., 2163., 2656., 2298.],\n",
      "        [2546., 2960., 2646., 3052.],\n",
      "        [  59., 1174.,  149., 1315.],\n",
      "        [ 398.,  662.,  536.,  787.],\n",
      "        [ 631., 1067.,  728., 1154.],\n",
      "        [2158., 3637., 2242., 3722.],\n",
      "        [1325., 3569., 1423., 3660.],\n",
      "        [2388., 1135., 2441., 1220.]]), 'labels': tensor([ 0,  0,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  3,  8,  7,\n",
      "        10, 10, 10, 10,  3, 11,  0,  3,  8, 10, 11, 11, 11, 10,  7,  6,  6,  6,\n",
      "         6,  6,  2,  2,  3,  2,  7,  7,  2,  7, 10, 10, 10,  7,  8,  8,  5,  5,\n",
      "         8,  7,  7,  7,  7,  2, 10, 10,  1,  7,  1,  2,  0,  7,  6,  4, 13])}, {'boxes': tensor([[1461., 3162., 1540., 3238.],\n",
      "        [ 876., 3041.,  953., 3144.],\n",
      "        [1325.,  472., 1716.,  710.],\n",
      "        [1183., 1603., 1376., 1793.],\n",
      "        [1453., 1755., 1887., 1921.],\n",
      "        [1390., 1622., 1668., 1754.],\n",
      "        [1471., 2191., 1699., 2359.],\n",
      "        [1231., 2163., 1415., 2295.],\n",
      "        [1180., 2456., 1389., 2679.],\n",
      "        [ 815., 1619.,  981., 1777.],\n",
      "        [1034., 1739., 1203., 1892.],\n",
      "        [1167., 1944., 1321., 2076.],\n",
      "        [1279., 2751., 1514., 2871.],\n",
      "        [1535., 2438., 1696., 2553.],\n",
      "        [1090., 2623., 1177., 2699.],\n",
      "        [ 805., 2936.,  884., 3024.],\n",
      "        [1017., 3074., 1126., 3218.],\n",
      "        [ 877., 2211., 1050., 2350.],\n",
      "        [1134.,  843., 1382., 1141.],\n",
      "        [ 879., 1303., 1067., 1514.],\n",
      "        [1882., 2216., 1951., 2293.],\n",
      "        [1836., 2403., 1924., 2505.],\n",
      "        [1630., 2679., 1770., 2789.],\n",
      "        [1030., 2337., 1103., 2462.],\n",
      "        [1037., 1939., 1163., 2117.],\n",
      "        [ 978., 2824., 1101., 2921.],\n",
      "        [1458., 3036., 1632., 3154.],\n",
      "        [ 585., 1085.,  710., 1200.],\n",
      "        [ 874., 2429., 1007., 2556.],\n",
      "        [1380., 1246., 1611., 1423.],\n",
      "        [1136., 1392., 1311., 1535.],\n",
      "        [1060., 1271., 1150., 1417.],\n",
      "        [1737., 3079., 1832., 3189.],\n",
      "        [1786., 2931., 1897., 3065.],\n",
      "        [ 774., 2056.,  877., 2171.],\n",
      "        [ 935., 1948., 1002., 2061.],\n",
      "        [ 774., 2319.,  947., 2405.],\n",
      "        [ 639., 1815.,  864., 1956.],\n",
      "        [1869., 1440., 2015., 1621.],\n",
      "        [2038.,  738., 2120.,  904.],\n",
      "        [1423., 2521., 1497., 2584.],\n",
      "        [1177., 2285., 1486., 2421.],\n",
      "        [1415.,  968., 1523., 1083.],\n",
      "        [ 762., 2919.,  833., 2993.],\n",
      "        [ 881., 2750.,  948., 2814.],\n",
      "        [ 841., 2802.,  970., 2959.],\n",
      "        [ 702., 3060.,  782., 3125.],\n",
      "        [1053., 2763., 1149., 2820.],\n",
      "        [ 521., 1326.,  636., 1395.],\n",
      "        [2230.,  265., 2391.,  480.],\n",
      "        [ 909., 2066.,  999., 2133.],\n",
      "        [ 708., 1198.,  828., 1262.],\n",
      "        [ 516., 1414.,  588., 1450.]]), 'labels': tensor([ 2, 10,  6,  3,  8,  8,  8,  8,  8,  6,  6,  6,  6,  3,  3,  3,  3,  3,\n",
      "         7,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  6,  6,  6,  8,  8,  8,  8,\n",
      "         8,  0,  2,  2,  6,  8,  6,  2,  2,  7,  8,  6,  7,  7,  8,  6,  6])}, {'boxes': tensor([[1.0000e+00, 3.2700e+02, 5.2600e+02, 6.8000e+02],\n",
      "        [3.8300e+02, 6.7200e+02, 7.2500e+02, 1.0220e+03],\n",
      "        [1.3900e+03, 4.3400e+02, 1.7310e+03, 6.3600e+02],\n",
      "        [8.9400e+02, 1.4300e+03, 1.4410e+03, 1.7130e+03],\n",
      "        [9.2200e+02, 3.0190e+03, 1.1160e+03, 3.2380e+03],\n",
      "        [1.5690e+03, 3.1900e+03, 1.7220e+03, 3.3350e+03],\n",
      "        [5.4200e+02, 3.4890e+03, 7.2100e+02, 3.6360e+03],\n",
      "        [1.1770e+03, 2.5720e+03, 1.2950e+03, 2.6760e+03],\n",
      "        [8.2000e+02, 2.3960e+03, 1.1470e+03, 2.6250e+03],\n",
      "        [2.0250e+03, 1.4970e+03, 2.2420e+03, 1.7290e+03],\n",
      "        [2.3680e+03, 1.2410e+03, 2.5660e+03, 1.4760e+03],\n",
      "        [1.9490e+03, 2.4560e+03, 2.0970e+03, 2.5950e+03],\n",
      "        [1.1340e+03, 2.6690e+03, 1.3260e+03, 2.8450e+03],\n",
      "        [1.9000e+02, 3.2560e+03, 4.6200e+02, 3.4810e+03],\n",
      "        [9.1200e+02, 3.4730e+03, 1.1340e+03, 3.5780e+03],\n",
      "        [2.6640e+03, 6.9900e+02, 2.9340e+03, 9.6000e+02],\n",
      "        [2.0460e+03, 2.2160e+03, 2.2730e+03, 2.4460e+03],\n",
      "        [1.4610e+03, 2.8160e+03, 1.6800e+03, 3.0060e+03],\n",
      "        [7.2100e+02, 3.1790e+03, 8.6900e+02, 3.3050e+03],\n",
      "        [2.5340e+03, 1.0570e+03, 2.6380e+03, 1.1600e+03],\n",
      "        [2.1280e+03, 1.2740e+03, 2.3160e+03, 1.4870e+03],\n",
      "        [1.8090e+03, 1.8510e+03, 2.0720e+03, 2.0410e+03],\n",
      "        [1.7720e+03, 1.6350e+03, 1.9920e+03, 1.7540e+03],\n",
      "        [1.3870e+03, 2.5810e+03, 1.5840e+03, 2.7140e+03],\n",
      "        [1.5300e+03, 2.4560e+03, 1.7540e+03, 2.6480e+03],\n",
      "        [9.8800e+02, 2.9260e+03, 1.1570e+03, 3.0280e+03],\n",
      "        [1.2030e+03, 3.3370e+03, 1.5710e+03, 3.5170e+03],\n",
      "        [1.5090e+03, 3.3150e+03, 1.5660e+03, 3.4480e+03],\n",
      "        [5.1800e+02, 2.9290e+03, 7.6100e+02, 3.0740e+03],\n",
      "        [0.0000e+00, 3.3780e+03, 1.1000e+02, 3.5580e+03],\n",
      "        [2.5600e+02, 1.8800e+03, 5.0900e+02, 2.0990e+03],\n",
      "        [5.7200e+02, 1.3640e+03, 7.8100e+02, 1.5150e+03],\n",
      "        [8.1000e+02, 2.2240e+03, 1.1080e+03, 2.3900e+03],\n",
      "        [1.7210e+03, 2.1070e+03, 1.9720e+03, 2.2780e+03],\n",
      "        [2.1920e+03, 1.7640e+03, 2.4920e+03, 1.9440e+03],\n",
      "        [2.2630e+03, 1.6040e+03, 2.4700e+03, 1.7520e+03],\n",
      "        [1.7390e+03, 6.9000e+02, 1.9180e+03, 8.6500e+02],\n",
      "        [1.4300e+03, 1.7690e+03, 1.5630e+03, 1.9160e+03],\n",
      "        [1.3210e+03, 1.9000e+03, 1.4560e+03, 2.0780e+03],\n",
      "        [4.0400e+02, 3.0360e+03, 7.3800e+02, 3.3730e+03],\n",
      "        [1.8470e+03, 1.0860e+03, 2.0820e+03, 1.3430e+03],\n",
      "        [1.5730e+03, 1.8060e+03, 1.8180e+03, 2.0430e+03],\n",
      "        [1.6810e+03, 2.0040e+03, 1.8670e+03, 2.0920e+03],\n",
      "        [1.7960e+03, 2.5390e+03, 1.9060e+03, 2.6380e+03],\n",
      "        [1.9000e+02, 1.1830e+03, 5.8000e+02, 1.5990e+03],\n",
      "        [0.0000e+00, 1.6880e+03, 2.8900e+02, 1.8720e+03],\n",
      "        [5.9000e+02, 1.1780e+03, 8.4000e+02, 1.4150e+03],\n",
      "        [1.2560e+03, 2.3070e+03, 1.3840e+03, 2.4550e+03],\n",
      "        [1.1080e+03, 2.0870e+03, 1.3150e+03, 2.3070e+03],\n",
      "        [4.9300e+02, 1.0230e+03, 6.6400e+02, 1.1480e+03],\n",
      "        [1.1500e+03, 7.0800e+02, 1.2830e+03, 8.2400e+02],\n",
      "        [2.3260e+03, 8.5700e+02, 2.5800e+03, 1.0710e+03],\n",
      "        [7.1600e+02, 2.8110e+03, 9.0400e+02, 2.9630e+03],\n",
      "        [2.9290e+03, 1.3630e+03, 3.0090e+03, 1.5630e+03],\n",
      "        [1.2700e+03, 6.4300e+02, 1.4330e+03, 7.8600e+02],\n",
      "        [1.5900e+02, 2.2120e+03, 3.5800e+02, 2.4060e+03],\n",
      "        [2.7300e+02, 2.1480e+03, 4.4500e+02, 2.2400e+03],\n",
      "        [1.5280e+03, 1.3260e+03, 1.7370e+03, 1.4870e+03],\n",
      "        [0.0000e+00, 2.4640e+03, 8.2000e+01, 2.5940e+03],\n",
      "        [2.0920e+03, 1.1370e+03, 2.2370e+03, 1.2390e+03],\n",
      "        [9.7300e+02, 1.8250e+03, 1.2250e+03, 2.0170e+03],\n",
      "        [3.8700e+02, 2.0660e+03, 5.6700e+02, 2.1910e+03],\n",
      "        [7.2900e+02, 1.7120e+03, 8.7800e+02, 1.8610e+03],\n",
      "        [2.5470e+03, 1.5840e+03, 2.6940e+03, 1.7620e+03]]), 'labels': tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  3,  3,  3,  3,  3,  6,  6,  6,\n",
      "         6,  6,  6,  6,  5,  5,  5,  5,  5,  2,  2,  2,  2,  2,  5,  5,  8,  8,\n",
      "         8,  8,  8, 14, 14, 14,  8,  6,  0,  0,  0,  7,  3,  1,  1, 14,  0,  0,\n",
      "         0,  3,  8,  5,  2,  6,  8,  8,  8, 14])}, {'boxes': tensor([[1.0270e+03, 3.5160e+03, 1.1140e+03, 3.6000e+03],\n",
      "        [1.4490e+03, 3.4250e+03, 1.5170e+03, 3.5240e+03],\n",
      "        [9.9100e+02, 1.3720e+03, 1.2790e+03, 1.6370e+03],\n",
      "        [1.2820e+03, 2.5280e+03, 1.5300e+03, 2.7100e+03],\n",
      "        [4.6800e+02, 2.7710e+03, 6.5200e+02, 2.9080e+03],\n",
      "        [2.4100e+02, 2.1660e+03, 4.7600e+02, 2.3880e+03],\n",
      "        [2.5800e+02, 3.4760e+03, 5.2100e+02, 3.6130e+03],\n",
      "        [7.8700e+02, 2.0090e+03, 9.3700e+02, 2.1730e+03],\n",
      "        [1.1060e+03, 3.3580e+03, 1.3020e+03, 3.5080e+03],\n",
      "        [4.3000e+01, 3.4380e+03, 1.4300e+02, 3.5540e+03],\n",
      "        [2.6300e+02, 3.0920e+03, 4.7200e+02, 3.2220e+03],\n",
      "        [0.0000e+00, 1.5960e+03, 3.4000e+02, 1.7540e+03],\n",
      "        [1.2300e+02, 2.4640e+03, 3.5500e+02, 2.6680e+03],\n",
      "        [4.5500e+02, 2.6580e+03, 6.0600e+02, 2.7650e+03],\n",
      "        [1.3540e+03, 9.2000e+02, 1.7060e+03, 1.1600e+03],\n",
      "        [1.1080e+03, 3.2700e+02, 1.5040e+03, 7.2500e+02],\n",
      "        [4.9900e+02, 8.8100e+02, 8.6800e+02, 1.2380e+03],\n",
      "        [9.8600e+02, 1.0630e+03, 1.2340e+03, 1.2690e+03],\n",
      "        [2.3600e+02, 6.0700e+02, 4.2700e+02, 7.6900e+02],\n",
      "        [8.9100e+02, 9.2200e+02, 9.7900e+02, 1.0680e+03],\n",
      "        [1.3410e+03, 1.4510e+03, 1.6960e+03, 1.6340e+03],\n",
      "        [1.2900e+03, 1.6390e+03, 1.9570e+03, 1.8930e+03],\n",
      "        [5.6000e+01, 2.9730e+03, 1.9000e+02, 3.0740e+03],\n",
      "        [8.0800e+02, 2.9130e+03, 1.1170e+03, 3.1570e+03],\n",
      "        [1.1160e+03, 2.6350e+03, 1.2570e+03, 2.7430e+03],\n",
      "        [8.5000e+02, 1.8330e+03, 1.1310e+03, 2.0610e+03],\n",
      "        [3.0900e+02, 1.2710e+03, 5.7000e+02, 1.5380e+03],\n",
      "        [7.1800e+02, 1.5530e+03, 9.5300e+02, 1.7360e+03],\n",
      "        [6.5900e+02, 3.4570e+03, 1.1090e+03, 3.6920e+03],\n",
      "        [5.0000e+00, 3.0090e+03, 1.4800e+02, 3.2890e+03],\n",
      "        [4.3500e+02, 2.3910e+03, 6.1100e+02, 2.5430e+03],\n",
      "        [5.6400e+02, 1.8000e+03, 8.2500e+02, 2.0810e+03],\n",
      "        [1.0440e+03, 2.7930e+03, 1.0470e+03, 2.7990e+03],\n",
      "        [1.4350e+03, 2.8810e+03, 1.5600e+03, 2.9780e+03],\n",
      "        [1.7040e+03, 2.5230e+03, 1.8140e+03, 2.6150e+03],\n",
      "        [1.7980e+03, 2.2450e+03, 1.9340e+03, 2.3620e+03],\n",
      "        [1.3590e+03, 2.2370e+03, 1.6660e+03, 2.5100e+03],\n",
      "        [8.9600e+02, 2.1470e+03, 1.1680e+03, 2.3590e+03],\n",
      "        [6.8800e+02, 2.6970e+03, 8.9900e+02, 2.7990e+03],\n",
      "        [7.8700e+02, 2.5540e+03, 1.0160e+03, 2.7420e+03],\n",
      "        [3.9600e+02, 2.9910e+03, 5.5200e+02, 3.1050e+03],\n",
      "        [1.0000e+00, 3.9300e+02, 2.7400e+02, 6.1600e+02],\n",
      "        [2.4040e+03, 4.6700e+02, 2.5700e+03, 6.1100e+02],\n",
      "        [8.5300e+02, 2.2900e+03, 1.1930e+03, 2.5250e+03],\n",
      "        [3.4200e+02, 1.9580e+03, 5.0600e+02, 2.0580e+03],\n",
      "        [3.8900e+02, 1.8100e+03, 5.4500e+02, 1.9360e+03],\n",
      "        [5.4000e+01, 1.9080e+03, 2.6400e+02, 2.0990e+03],\n",
      "        [1.5450e+03, 0.0000e+00, 2.0350e+03, 2.6600e+02],\n",
      "        [1.5350e+03, 5.6700e+02, 1.7240e+03, 7.4300e+02],\n",
      "        [1.3700e+02, 3.1880e+03, 2.3700e+02, 3.2740e+03]]), 'labels': tensor([2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 7, 7, 8, 8, 8, 8, 8, 2, 6,\n",
      "        6, 6, 6, 5, 5, 7, 7, 7, 7, 7, 7, 7, 6, 5, 5, 5, 5, 0, 2, 0, 8, 8, 8, 6,\n",
      "        6, 6])}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import xml.etree.ElementTree as ET\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Define class mapping for climbing holds\n",
    "LABEL_MAP = {\n",
    "    \"red_hold\": 0,\n",
    "    \"blue_hold\": 1,\n",
    "    \"yellow_hold\": 2,\n",
    "    \"green_hold\": 3,\n",
    "    \"orange_hold\": 4,\n",
    "    \"purple_hold\": 5,\n",
    "    \"black_hold\": 6,\n",
    "    \"white_hold\": 7,\n",
    "    \"gray_hold\": 8,\n",
    "    \"brown_hold\": 9,\n",
    "    \"pink_hold\": 10,\n",
    "    \"teal_hold\": 11,\n",
    "    \"cyan_hold\": 12,\n",
    "    \"magenta_hold\": 13,\n",
    "    \"lightyellow_hold\": 14\n",
    "}\n",
    "\n",
    "class ClimbingHoldDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotation_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        ann_path = os.path.join(self.annotation_dir, os.path.splitext(img_name)[0] + \".xml\")\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Parse XML annotation\n",
    "        labels = []\n",
    "        boxes = []\n",
    "        if os.path.exists(ann_path):\n",
    "            tree = ET.parse(ann_path)\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall(\"object\"):\n",
    "                label = obj.find(\"name\").text\n",
    "                if label in LABEL_MAP:\n",
    "                    bbox = obj.find(\"bndbox\")\n",
    "                    xmin = int(bbox.find(\"xmin\").text)\n",
    "                    ymin = int(bbox.find(\"ymin\").text)\n",
    "                    xmax = int(bbox.find(\"xmax\").text)\n",
    "                    ymax = int(bbox.find(\"ymax\").text)\n",
    "                    \n",
    "                    boxes.append([xmin, ymin, xmax, ymax])\n",
    "                    labels.append(LABEL_MAP[label])\n",
    "        \n",
    "        # Convert to PyTorch tensor\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0, 4), dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64) if labels else torch.zeros((0,), dtype=torch.int64)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "# Define dataset transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to match MobileNet input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Example usage\n",
    "image_dir = \"C:/Users/shawn/Downloads/Archive (3)\"\n",
    "annotation_dir = \"C:/Users/shawn/Downloads/labels_my-project-name_2025-02-06-05-20-57 2/labels_my-project-name_2025-02-06-05-20-57\"\n",
    "dataset = ClimbingHoldDataset(image_dir, annotation_dir, transform=transform)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [{\"boxes\": item[1][\"boxes\"], \"labels\": item[1][\"labels\"]} for item in batch]\n",
    "    return images, targets\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Verify dataset\n",
    "for images, targets in dataloader:\n",
    "    print(\"Batch images shape:\", len(images))\n",
    "    print(\"Batch targets:\", targets)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f53647f-813b-465c-965d-ebe1450713e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shawn\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shawn\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\" to C:\\Users\\shawn/.cache\\torch\\hub\\checkpoints\\fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\n",
      "100%|| 74.2M/74.2M [00:13<00:00, 5.64MB/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LABEL_MAP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mfasterrcnn_mobilenet_v3_large_fpn(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Adjust output layers for our climbing hold classes\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(LABEL_MAP) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# +1 for background\u001b[39;00m\n\u001b[0;32m      8\u001b[0m in_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mroi_heads\u001b[38;5;241m.\u001b[39mbox_predictor\u001b[38;5;241m.\u001b[39mcls_score\u001b[38;5;241m.\u001b[39min_features\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mroi_heads\u001b[38;5;241m.\u001b[39mbox_predictor \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mfaster_rcnn\u001b[38;5;241m.\u001b[39mFastRCNNPredictor(in_features, num_classes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LABEL_MAP' is not defined"
     ]
    }
   ],
   "source": [
    "import torchvision.models.detection as detection\n",
    "\n",
    "# Load MobileNetV3-based Faster R-CNN model\n",
    "model = detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "\n",
    "# Adjust output layers for our climbing hold classes\n",
    "num_classes = len(LABEL_MAP) + 1  # +1 for background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8784327-ed38-4aed-a466-cc56a98785e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
